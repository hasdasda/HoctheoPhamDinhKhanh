{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfu-zXiSOPip",
        "outputId": "73d5915c-6b69-401b-aa47-07b1cda7d3d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.5.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.2)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2024.9.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.5.0)\n",
            "Downloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.11 underthesea-6.8.4 underthesea-core-1.0.4\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn\n",
        "!pip install underthesea\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMC2sGPsJ3CX"
      },
      "source": [
        "Hàm biểu diễn One-hot vector:\n",
        "Trong python chúng ta có thể biến đổi các từ sang dạng one-hot vector thông qua hàm OneHotEncoder của sklearn. Nhưng trước tiên ta cần gán index cho các class bằng LabelEncoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caGDVkAAHZKy",
        "outputId": "c2c32259-ac9d-4654-cde7-23630900e8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class of words: ['anh' 'bạn bè' 'em' 'gia đình']\n",
            "Convert to number: [0 2 3 1 0 2]\n",
            "Invert into classes:  ['anh' 'em' 'gia đình' 'bạn bè' 'anh' 'em']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "words =['anh','em','gia đình','bạn bè','anh','em']\n",
        "le.fit(words)\n",
        "print('Class of words:', le.classes_)\n",
        "# Biến đổi sang dạng số\n",
        "x = le.transform(words)\n",
        "print('Convert to number:', x)\n",
        "# Biến đổi lại sang class\n",
        "print('Invert into classes: ', le.inverse_transform(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFS8Zq5JRKy0"
      },
      "source": [
        "Thực hiện OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXFw4d6RJU9",
        "outputId": "48f4fcb1-25d3-4f3b-8f7c-9b70e7787577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes_indices: [('anh', 0), ('bạn bè', 1), ('em', 2), ('gia đình', 3)]\n",
            "One-hot categories and indices: [array(['anh', 'bạn bè', 'em', 'gia đình'], dtype=object), array([0, 1, 2, 3], dtype=object)]\n",
            "Word and corresponding indices: [('anh', 0), ('em', 2), ('gia đình', 3), ('bạn bè', 1), ('anh', 0), ('em', 2)]\n",
            "Transform word into one-hot matrices: \n",
            " [[1. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 1. 0.]]\n",
            "Inverse transform to categories from one-hot matrices:\n",
            " [['anh' 0]\n",
            " ['em' 2]\n",
            " ['gia đình' 3]\n",
            " ['bạn bè' 1]\n",
            " ['anh' 0]\n",
            " ['em' 2]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "oh = OneHotEncoder()\n",
        "classes_indices = list(zip(le.classes_, np.arange(len(le.classes_))))\n",
        "print('Classes_indices:', classes_indices)\n",
        "oh.fit(classes_indices)\n",
        "print('One-hot categories and indices:', oh.categories_)\n",
        "# Biến đổi list words sang dạng one-hot\n",
        "words_indices = list(zip(words,x))\n",
        "print('Word and corresponding indices:', words_indices)\n",
        "one_hot = oh.transform(words_indices).toarray()\n",
        "print('Transform word into one-hot matrices: \\n', one_hot)\n",
        "print('Inverse transform to categories from one-hot matrices:\\n', oh.inverse_transform(one_hot))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZGQhdeNWfLs"
      },
      "source": [
        "Singular Value Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ-VnMHmXsPK",
        "outputId": "a9bec6e0-a750-4ad7-b6c9-858a8fe19a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization of sentences:  ['Khoa học', 'dữ liệu', 'là', 'một', 'lĩnh vực', 'đòi hỏi', 'kiến tức', 'về', 'toán', 'và', 'lập trình', '.', 'Tôi', 'rát', 'yêu thích', 'Khoa học', 'dữ liệu', '.']\n"
          ]
        }
      ],
      "source": [
        "import scipy.linalg as ln\n",
        "import numpy as np\n",
        "from underthesea import word_tokenize\n",
        "sentence = 'Khoa học dữ liệu là một lĩnh vực đòi hỏi kiến tức về toán và lập trình. Tôi rát yêu thích Khoa học dữ liệu.'\n",
        "token = word_tokenize(sentence)\n",
        "# Tokenize câu search\n",
        "print('Tokenization of sentences: ', token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2NCCiczcY_u"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtwGLLaJVlSy",
        "outputId": "b266effc-be9a-4cbe-be60-c561d14bcfba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "# Tạo ma trận coherence dưới dạng sparse thông qua khai báo vị trí khác 0 của trục x và trục y\n",
        "row = [0,1,2,3,4,5,6,7,8,9,11,12,13]\n",
        "col = [i for i in range(14) if i != 0 ]\n",
        "data = [2] + [1] * 12\n",
        "X = coo_matrix((data,(row,col)), shape=(15,15))\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS0J-StomnFN",
        "outputId": "fe4817f5-3dea-4016-fdc4-4e5cbfe441d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "# Tạo ma trận coherence dưới dạng sparse thông qua khai báo vị trí khác 0 của trục x và y\n",
        "row = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13]\n",
        "col = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14]\n",
        "data =      [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "\n",
        "X = coo_matrix((data, (row, col)), shape=(15, 15)).toarray()\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIo7mmJ9Jzy3"
      },
      "source": [
        "Xem về coo_matrix ở trong link sau https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMDLPRrPdM1d",
        "outputId": "a2b792b9-653a-4fbc-9a55-79c648c9fbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of U:  (15, 15)\n",
            "Length of diagonal:  15\n",
            "Shape of V:  (15, 15)\n"
          ]
        }
      ],
      "source": [
        "# Thực hiện phân tích suy biến:\n",
        "U, S_diag, V = ln.svd(X)\n",
        "print('Shape of U: ', U.shape)\n",
        "print('Length of diagonal: ', len(S_diag))\n",
        "print('Shape of V: ', V.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PFJFo-ql8Wh",
        "outputId": "5b12d8a8-e886-4710-cd4e-0777312322b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S_truncate: \n",
            " [[2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Word Embedding 6 dimensionality: \n",
            " [[0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "S_truncate = np.zeros(shape = (6,15))\n",
        "np.fill_diagonal(S_truncate, S_diag[:6])\n",
        "print('S_truncate: \\n', S_truncate)\n",
        "print('Word Embedding 6 dimensionality: \\n', np.dot(S_truncate, V))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aJNPBMkotzC"
      },
      "source": [
        "2.2. Phương pháp auto encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "91zT8duGoyrw",
        "outputId": "7708c588-1f02-42d7-c709-51c7f7317654"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m96\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m105\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m441\u001b[0m (1.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">441</span> (1.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m441\u001b[0m (1.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">441</span> (1.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 2.8156\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 2.8649  \n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 2.7770 \n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 2.3665 \n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 2.4155 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d49701952d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from keras.layers import Dense, Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "\n",
        "def autoencoder(input_unit, hidden_unit):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_unit, input_shape = (15,), activation = 'relu'))\n",
        "    model.add(Dense(hidden_unit, activation = 'relu'))\n",
        "    model.add(Dense(input_unit, activation = 'softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),\n",
        "                 metrics = ['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model_auto = autoencoder(input_unit = 15, hidden_unit = 6)\n",
        "\n",
        "model_auto.fit(X, X, epochs = 5, batch_size = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5XkGuiky5m4",
        "outputId": "0eadad79-bae0-4b85-b093-6e58715548d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embedding_matrix:  (15, 6)\n",
            "Embedding matrix: \n",
            " [[-0.3458184  -0.44023168 -0.22893927 -0.27206817  0.08131414 -0.24407724]\n",
            " [ 0.40836078 -0.22711517 -0.20640539  0.48638138 -0.4496564   0.01588943]\n",
            " [ 0.49877906  0.31958273  0.2576014  -0.41180456  0.03209291 -0.34454432]\n",
            " [-0.21179658  0.16201234 -0.01677432  0.1921186   0.20270565 -0.17666559]\n",
            " [ 0.3536362   0.00909845  0.07791119 -0.37504405 -0.09228531  0.35350338]\n",
            " [ 0.5053984  -0.5053971   0.31614625  0.08735497 -0.42670795 -0.3657482 ]\n",
            " [-0.39526019 -0.35198325 -0.37643442  0.31789255 -0.26221922 -0.30623192]\n",
            " [ 0.02981994 -0.26254138 -0.4472761  -0.4787548  -0.24637946  0.41811097]\n",
            " [ 0.37217504 -0.268757    0.51019853  0.15294208 -0.3375232   0.04463334]\n",
            " [ 0.31694734  0.39002243  0.35158437  0.23327033  0.4572217  -0.15579818]\n",
            " [ 0.48512098 -0.04649047 -0.26412567  0.52948916 -0.00691483  0.40648988]\n",
            " [ 0.3515705  -0.31629837  0.06446084  0.30173212 -0.31073895 -0.30081078]\n",
            " [-0.3051162   0.47326908 -0.29120123  0.18179156 -0.13059354 -0.4453102 ]\n",
            " [ 0.3657501   0.3492177  -0.14049783  0.34604186  0.36712494 -0.05368106]\n",
            " [-0.41861576  0.28579733 -0.2601828   0.08186503  0.3832539   0.48494542]]\n",
            "Bias: \n",
            " [-0.01101942  0.01431363  0.009181   -0.00250837  0.00621659  0.00641747]\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = model_auto.layers[1].get_weights()[0]\n",
        "bias = model_auto.layers[1].get_weights()[1]\n",
        "print('Shape of embedding_matrix: ', embedding_matrix.shape)\n",
        "print('Embedding matrix: \\n', embedding_matrix)\n",
        "print('Bias: \\n', bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jSp0cOoY0x3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c28b93-1c98-4d1f-a5fe-58f88595a858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.10005927"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from numpy.linalg import norm\n",
        "def cosine(x,y):\n",
        "  cos_sim = np.dot(x,y)/(norm(x)*norm(y))\n",
        "  return cos_sim\n",
        "# Véc tơ biểu diễn từ khoa học\n",
        "e0 = list(embedding_matrix[:, 0])\n",
        "# Véc tơ biểu diễn từ dữ liệu\n",
        "e1 = list(embedding_matrix[:, 1])\n",
        "# Quan hệ tương quan ngữ nghĩa giữa từ khoa học và dữ liệu\n",
        "cosine(e0, e1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tìm từ tương quan nhất với một từ thông qua khoảng cách cosine_similarity"
      ],
      "metadata": {
        "id": "UgZlfaQ5qORf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Từ có khoảng cách lớn nhất với từ khoa học theo thứ tự\n",
        "cosine= [cosine(e0)]"
      ],
      "metadata": {
        "id": "ythJ0z9Zqboe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}