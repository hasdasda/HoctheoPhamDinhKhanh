{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "vietocr_gettingstart.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasdasda/HoctheoPhamDinhKhanh/blob/main/vietocr_gettingstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPgu4i1yvhub"
      },
      "source": [
        "\n",
        "# Introduction\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/pbcquoc/vietocr/master/image/vietocr.jpg\" width=\"512\" height=\"512\">\n",
        "</p>\n",
        "This notebook describe how you can use VietOcr to train OCR model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjMKMc51-bFV",
        "outputId": "1ca93ca1-4d85-4ffc-ceac-6858223ae271"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEBHav_aljVN"
      },
      "source": [
        "! pip install --quiet vietocr"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "XOW6Vyh5-_wt",
        "outputId": "03cf2521-d317-410d-868b-9138358470a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.2.0)\n",
            "Collecting Pillow\n",
            "  Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Installing collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 10.2.0\n",
            "    Uninstalling pillow-10.2.0:\n",
            "      Successfully uninstalled pillow-10.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "vietocr 0.3.13 requires pillow==10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-11.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "8003bef2226f4972a16e4e87366a0efc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS1cz5tKxio7"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsuT5Sa-xio8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from vietocr.tool.predictor import Predictor\n",
        "from vietocr.tool.config import Cfg"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7u5QgLWxipC"
      },
      "source": [
        "config = Cfg.load_config_from_name('vgg_transformer')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5JIpythxipL"
      },
      "source": [
        "Change weights to your weights or using default weights from our pretrained model. Path can be url or local file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjiubW0gxipL"
      },
      "source": [
        "# config['weights'] = './weights/transformerocr.pth'\n",
        "config['cnn']['pretrained']=False\n",
        "config['device'] = 'cuda:0'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjHpH99TxipQ",
        "outputId": "cad4ed32-86bc-4004-9b69-d703fa108c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "detector = Predictor(config)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "18533it [00:09, 1995.62it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/vietocr/tool/predictor.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(weights, map_location=torch.device(device)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHtnhkpsxipZ"
      },
      "source": [
        "# ! wget https://vocr.vn/data/vietocr/sample.zip\n",
        "# ! unzip  -qq -o sample.zip"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGpmXki1xipe"
      },
      "source": [
        "# ! ls sample | shuf |head -n 5"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B95BBXNExipj"
      },
      "source": [
        "# img = './sample/031189003299.jpeg'\n",
        "# img = Image.open(img)\n",
        "# plt.imshow(img)\n",
        "# s = detector.predict(img)\n",
        "# s"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9zjgHwN2vuC"
      },
      "source": [
        "# Download sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMMAabbInNe3"
      },
      "source": [
        "# ! wget https://vocr.vn/data/vietocr/data_line.zip"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEBWugoTnvy0"
      },
      "source": [
        "# ! unzip -qq -o ./data_line.zip"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1lxSkEj20y0"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MWgUSotv1sN"
      },
      "source": [
        "\n",
        "\n",
        "1.   Load your config\n",
        "2.   Train model using your dataset above\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuzRB0rxwC3m"
      },
      "source": [
        "Load the default config, we adopt VGG for image feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMwREzEvm_jd"
      },
      "source": [
        "from vietocr.tool.config import Cfg\n",
        "from vietocr.model.trainer import Trainer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oKRCu2ewNE4"
      },
      "source": [
        "# Change the config\n",
        "\n",
        "* *data_root*: the folder save your all images\n",
        "* *train_annotation*: path to train annotation\n",
        "* *valid_annotation*: path to valid annotation\n",
        "* *print_every*: show train loss at every n steps\n",
        "* *valid_every*: show validation loss at every n steps\n",
        "* *iters*: number of iteration to train your model\n",
        "* *export*: export weights to folder that you can use for inference\n",
        "* *metrics*: number of sample in validation annotation you use for computing full_sequence_accuracy, for large dataset it will take too long, then you can reuduce this number\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56VBD-Xy_ztj"
      },
      "source": [
        "config = Cfg.load_config_from_name('vgg_transformer')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceKcT5eOnJ1G"
      },
      "source": [
        "\n",
        "dataset_params = {\n",
        "    'name':'hw',\n",
        "    'data_root':'/content/drive/MyDrive/Data',\n",
        "    'train_annotation':'train_line_annotation.txt',\n",
        "    'valid_annotation':'test_line_annotation.txt'\n",
        "}\n",
        "\n",
        "params = {\n",
        "         'print_every':100,\n",
        "         'valid_every':1,\n",
        "          'iters':1000,\n",
        "          'checkpoint':'./checkpoint/transformerocr_checkpoint.pth',\n",
        "          'export':'./weights/transformerocr.pth',\n",
        "          'metrics': 10000\n",
        "         }\n",
        "\n",
        "config['trainer'].update(params)\n",
        "config['dataset'].update(dataset_params)\n",
        "config['device'] = 'cuda:0'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufc86K0axiqN"
      },
      "source": [
        "you can change any of these params in this full list below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwHpqqQEnHv1",
        "outputId": "03c539e0-496d-4b05-9430-55112c068593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "config"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vocab': 'aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ ',\n",
              " 'device': 'cuda:0',\n",
              " 'seq_modeling': 'transformer',\n",
              " 'transformer': {'d_model': 256,\n",
              "  'nhead': 8,\n",
              "  'num_encoder_layers': 6,\n",
              "  'num_decoder_layers': 6,\n",
              "  'dim_feedforward': 2048,\n",
              "  'max_seq_length': 1024,\n",
              "  'pos_dropout': 0.1,\n",
              "  'trans_dropout': 0.1},\n",
              " 'optimizer': {'max_lr': 0.0003, 'pct_start': 0.1},\n",
              " 'trainer': {'batch_size': 32,\n",
              "  'print_every': 200,\n",
              "  'valid_every': 3000,\n",
              "  'iters': 20000,\n",
              "  'export': './weights/transformerocr.pth',\n",
              "  'checkpoint': './checkpoint/transformerocr_checkpoint.pth',\n",
              "  'log': './train.log',\n",
              "  'metrics': 10000},\n",
              " 'dataset': {'name': 'hw',\n",
              "  'data_root': '/content/drive/MyDrive/Data',\n",
              "  'train_annotation': 'train_line_annotation.txt',\n",
              "  'valid_annotation': 'test_line_annotation.txt',\n",
              "  'image_height': 32,\n",
              "  'image_min_width': 32,\n",
              "  'image_max_width': 512},\n",
              " 'dataloader': {'num_workers': 3, 'pin_memory': True},\n",
              " 'aug': {'image_aug': True, 'masked_language_model': True},\n",
              " 'predictor': {'beamsearch': False},\n",
              " 'quiet': False,\n",
              " 'pretrain': 'https://vocr.vn/data/vietocr/vgg_transformer.pth',\n",
              " 'weights': 'https://vocr.vn/data/vietocr/vgg_transformer.pth',\n",
              " 'backbone': 'vgg19_bn',\n",
              " 'cnn': {'pretrained': True,\n",
              "  'ss': [[2, 2], [2, 2], [2, 1], [2, 1], [1, 1]],\n",
              "  'ks': [[2, 2], [2, 2], [2, 1], [2, 1], [1, 1]],\n",
              "  'hidden': 256}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dxTXpqa3Hd3"
      },
      "source": [
        "You should train model from our pretrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtOyT8Cpo1gl",
        "outputId": "f2ef764a-2359-4629-acd4-e5dd369d0236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "trainer = Trainer(config, pretrained=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weight /tmp/vgg_transformer.pth exsits. Ignore download!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Create train_hw: 100%|██████████████████████████████████████████████| 17/17 [00:04<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset with 16 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "train_hw build cluster: 100%|████████████████████████████████████| 16/16 [00:00<00:00, 49710.27it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Create valid_hw: 100%|████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset with 1 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "valid_hw build cluster: 100%|███████████████████████████████████████| 1/1 [00:00<00:00, 8507.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvG8aEOlBmVg"
      },
      "source": [
        "Save model configuration for inference, load_config_from_file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Potem8SsojYM"
      },
      "source": [
        "trainer.config.save('config.yml')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyL8nmmTxiqV"
      },
      "source": [
        "Visualize your dataset to check data augmentation is appropriate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OET9Vh8XxiqV"
      },
      "source": [
        "trainer.visualize_dataset()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EkP2h64xiqZ"
      },
      "source": [
        "Train now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpZEz_DPpV6y",
        "outputId": "12479077-efd8-41d6-aac0-f2c79dc7c6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vietocr/model/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vietocr/model/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mdata_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtotal_loader_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1436\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m             \u001b[0;31m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iig6gpyb3jtz"
      },
      "source": [
        "Visualize prediction from our trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zeai5W02qXA9"
      },
      "source": [
        "trainer.visualize_prediction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bAXlHJv3ryW"
      },
      "source": [
        "Compute full seq accuracy for full valid dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM806O42q_aT"
      },
      "source": [
        "trainer.precision()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}